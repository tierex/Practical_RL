{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov decision process\n",
    "\n",
    "This week's methods are all built to solve __M__arkov __D__ecision __P__rocesses. In the broadest sense, an MDP is defined by how it changes states and how rewards are computed.\n",
    "\n",
    "State transition is defined by $P(s' |s,a)$ - how likely areare you to end at state $s'$ if you take action $a$ from state $s$. Now there's more than one way to define rewards, but we'll use $r(s,a,s')$ function for convenience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For starters, let's define a simple MDP from this picture:\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Markov_Decision_Process.svg/800px-Markov_Decision_Process.svg.png' width=300px>\n",
    "_img by MistWiz (Own work) [Public domain], via Wikimedia Commons_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_probs = {\n",
    "  's0':{\n",
    "    'a0': {'s0': 0.5, 's2': 0.5},\n",
    "    'a1': {'s2': 1}\n",
    "  },\n",
    "  's1':{\n",
    "    'a0': {'s0': 0.7, 's1': 0.1, 's2': 0.2},\n",
    "    'a1': {'s1': 0.95, 's2': 0.05}\n",
    "  },\n",
    "  's2':{\n",
    "    'a0': {'s0': 0.4, 's1': 0.6},\n",
    "    'a1': {'s0': 0.3, 's1': 0.3, 's2':0.4}\n",
    "  }\n",
    "}\n",
    "rewards = {\n",
    "  's1': {'a0': {'s0': +5}},\n",
    "  's2': {'a1': {'s0': -1}}\n",
    "}\n",
    "\n",
    "from mdp import MDP\n",
    "mdp = MDP(transition_probs, rewards, initial_state='s0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "??MDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use MDP just as any other gym environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial state = s0\n",
      "next_state = s2, reward = 0.0, done = False\n"
     ]
    }
   ],
   "source": [
    "print('initial state =', mdp.reset())\n",
    "next_state, reward, done, info = mdp.step('a1')\n",
    "print('next_state = %s, reward = %s, done = %s' % (next_state, reward, done))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but it also has other methods that you'll need for Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mdp.get_all_states = ('s0', 's1', 's2')\n",
      "mdp.get_possible_actions('s1') =  ('a0', 'a1')\n",
      "mdp.get_next_states('s1', 'a0') =  {'s0': 0.7, 's1': 0.1, 's2': 0.2}\n",
      "mdp.get_reward('s1', 'a0', 's0') =  5\n",
      "mdp.get_transition_prob('s1', 'a0', 's0') =  0.7\n"
     ]
    }
   ],
   "source": [
    "print(\"mdp.get_all_states =\", mdp.get_all_states())\n",
    "print(\"mdp.get_possible_actions('s1') = \", mdp.get_possible_actions('s1'))\n",
    "print(\"mdp.get_next_states('s1', 'a0') = \", mdp.get_next_states('s1', 'a0'))\n",
    "print(\"mdp.get_reward('s1', 'a0', 's0') = \", mdp.get_reward('s1', 'a0', 's0'))\n",
    "print(\"mdp.get_transition_prob('s1', 'a0', 's0') = \", mdp.get_transition_prob('s1', 'a0', 's0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Iteration\n",
    "\n",
    "Now let's build something to solve this MDP. The simplest algorithm so far is __V__alue __I__teration\n",
    "\n",
    "Here's the pseudo-code for VI:\n",
    "\n",
    "---\n",
    "\n",
    "`1.` Initialize $V^{(0)}(s)=0$, for all $s$\n",
    "\n",
    "`2.` For $i=0, 1, 2, \\dots$\n",
    " \n",
    "`3.` $ \\quad V_{(i+1)}(s) = \\max_a \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')]$, for all $s$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's write a function to compute the state-action value function $Q^{\\pi}$, defined as follows\n",
    "\n",
    "$$Q_i(s, a) = \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_value(mdp, state_values, state, action, gamma):\n",
    "    \"\"\" Computes Q(s,a) as in formula above \"\"\"\n",
    "    q = 0\n",
    "    for next_state, prob in mdp.get_next_states(state, action).items():\n",
    "        reward = mdp.get_reward(state,action,next_state)\n",
    "        q+= prob*(reward + gamma* state_values[next_state])\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s0 0.7\n",
      "s1 0.1\n",
      "s2 0.2\n"
     ]
    }
   ],
   "source": [
    "for ns, np in mdp.get_next_states('s1', 'a0').items():\n",
    "    print(ns,np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'s0': 0, 's1': 1, 's2': 2}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "test_Vs = {s : i for i, s in enumerate(mdp.get_all_states())}\n",
    "print(test_Vs)\n",
    "assert np.allclose(get_action_value(mdp, test_Vs, 's2', 'a1', 0.9), 0.69)\n",
    "assert np.allclose(get_action_value(mdp, test_Vs, 's1', 'a0', 0.9), 3.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using $Q(s,a)$ we can now define the \"next\" V(s) for value iteration.\n",
    " $$V_{(i+1)}(s) = \\max_a \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')] = \\max_a Q_i(s,a)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_state_value(mdp, state_values, state, gamma):\n",
    "    \"\"\" Computes next V(s) as per formula above. Please do not change state_values in process. \"\"\"\n",
    "    if mdp.is_terminal(state): return 0\n",
    "    n_actions = len(mdp.get_possible_actions(state))\n",
    "    q_sa = np.zeros(n_actions)\n",
    "    for ind, action in enumerate(mdp.get_possible_actions(state)):\n",
    "        q_sa[ind] = get_action_value(mdp, state_values, state, action, gamma)\n",
    "    return  np.max(q_sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 a0\n",
      "1 a1\n"
     ]
    }
   ],
   "source": [
    "for i,a in enumerate(mdp.get_possible_actions('s0')):\n",
    "    print(i,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Vs_vopy = dict(test_Vs)\n",
    "assert np.allclose(get_new_state_value(mdp, test_Vs, 's0', 0.9), 1.8)\n",
    "assert np.allclose(get_new_state_value(mdp, test_Vs, 's2', 0.9), 0.69)\n",
    "assert test_Vs == test_Vs_vopy, \"please do not change state_values in get_new_state_value\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's combine everything we wrote into a working value iteration algo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 3.50000   |   V(s0) = 0.000   V(s1) = 0.000   V(s2) = 0.000\n",
      "\n",
      "iter    1   |   diff: 1.89000   |   V(s0) = 0.000   V(s1) = 3.500   V(s2) = 0.000\n",
      "\n",
      "iter    2   |   diff: 1.70100   |   V(s0) = 0.000   V(s1) = 3.815   V(s2) = 1.890\n",
      "\n",
      "iter    3   |   diff: 1.13542   |   V(s0) = 1.701   V(s1) = 4.184   V(s2) = 2.060\n",
      "\n",
      "iter    4   |   diff: 0.73024   |   V(s0) = 1.854   V(s1) = 5.319   V(s2) = 2.871\n",
      "\n",
      "iter    5   |   diff: 0.61135   |   V(s0) = 2.584   V(s1) = 5.664   V(s2) = 3.540\n",
      "\n",
      "iter    6   |   diff: 0.54664   |   V(s0) = 3.186   V(s1) = 6.275   V(s2) = 3.989\n",
      "\n",
      "iter    7   |   diff: 0.49198   |   V(s0) = 3.590   V(s1) = 6.790   V(s2) = 4.535\n",
      "\n",
      "iter    8   |   diff: 0.42210   |   V(s0) = 4.082   V(s1) = 7.189   V(s2) = 4.959\n",
      "\n",
      "iter    9   |   diff: 0.36513   |   V(s0) = 4.463   V(s1) = 7.611   V(s2) = 5.352\n",
      "\n",
      "iter   10   |   diff: 0.32862   |   V(s0) = 4.816   V(s1) = 7.960   V(s2) = 5.717\n",
      "\n",
      "iter   11   |   diff: 0.29262   |   V(s0) = 5.145   V(s1) = 8.280   V(s2) = 6.032\n",
      "\n",
      "iter   12   |   diff: 0.26189   |   V(s0) = 5.429   V(s1) = 8.572   V(s2) = 6.323\n",
      "\n",
      "iter   13   |   diff: 0.23503   |   V(s0) = 5.691   V(s1) = 8.830   V(s2) = 6.584\n",
      "\n",
      "iter   14   |   diff: 0.21124   |   V(s0) = 5.925   V(s1) = 9.065   V(s2) = 6.817\n",
      "\n",
      "iter   15   |   diff: 0.19012   |   V(s0) = 6.135   V(s1) = 9.276   V(s2) = 7.028\n",
      "\n",
      "iter   16   |   diff: 0.17091   |   V(s0) = 6.325   V(s1) = 9.465   V(s2) = 7.218\n",
      "\n",
      "iter   17   |   diff: 0.15366   |   V(s0) = 6.496   V(s1) = 9.636   V(s2) = 7.388\n",
      "\n",
      "iter   18   |   diff: 0.13830   |   V(s0) = 6.649   V(s1) = 9.790   V(s2) = 7.542\n",
      "\n",
      "iter   19   |   diff: 0.12445   |   V(s0) = 6.788   V(s1) = 9.928   V(s2) = 7.680\n",
      "\n",
      "iter   20   |   diff: 0.11200   |   V(s0) = 6.912   V(s1) = 10.052   V(s2) = 7.805\n",
      "\n",
      "iter   21   |   diff: 0.10079   |   V(s0) = 7.024   V(s1) = 10.164   V(s2) = 7.917\n",
      "\n",
      "iter   22   |   diff: 0.09071   |   V(s0) = 7.125   V(s1) = 10.265   V(s2) = 8.017\n",
      "\n",
      "iter   23   |   diff: 0.08164   |   V(s0) = 7.216   V(s1) = 10.356   V(s2) = 8.108\n",
      "\n",
      "iter   24   |   diff: 0.07347   |   V(s0) = 7.297   V(s1) = 10.437   V(s2) = 8.190\n",
      "\n",
      "iter   25   |   diff: 0.06612   |   V(s0) = 7.371   V(s1) = 10.511   V(s2) = 8.263\n",
      "\n",
      "iter   26   |   diff: 0.05951   |   V(s0) = 7.437   V(s1) = 10.577   V(s2) = 8.329\n",
      "\n",
      "iter   27   |   diff: 0.05356   |   V(s0) = 7.496   V(s1) = 10.636   V(s2) = 8.389\n",
      "\n",
      "iter   28   |   diff: 0.04820   |   V(s0) = 7.550   V(s1) = 10.690   V(s2) = 8.442\n",
      "\n",
      "iter   29   |   diff: 0.04338   |   V(s0) = 7.598   V(s1) = 10.738   V(s2) = 8.491\n",
      "\n",
      "iter   30   |   diff: 0.03904   |   V(s0) = 7.641   V(s1) = 10.782   V(s2) = 8.534\n",
      "\n",
      "iter   31   |   diff: 0.03514   |   V(s0) = 7.681   V(s1) = 10.821   V(s2) = 8.573\n",
      "\n",
      "iter   32   |   diff: 0.03163   |   V(s0) = 7.716   V(s1) = 10.856   V(s2) = 8.608\n",
      "\n",
      "iter   33   |   diff: 0.02846   |   V(s0) = 7.747   V(s1) = 10.887   V(s2) = 8.640\n",
      "\n",
      "iter   34   |   diff: 0.02562   |   V(s0) = 7.776   V(s1) = 10.916   V(s2) = 8.668\n",
      "\n",
      "iter   35   |   diff: 0.02306   |   V(s0) = 7.801   V(s1) = 10.941   V(s2) = 8.694\n",
      "\n",
      "iter   36   |   diff: 0.02075   |   V(s0) = 7.824   V(s1) = 10.964   V(s2) = 8.717\n",
      "\n",
      "iter   37   |   diff: 0.01867   |   V(s0) = 7.845   V(s1) = 10.985   V(s2) = 8.738\n",
      "\n",
      "iter   38   |   diff: 0.01681   |   V(s0) = 7.864   V(s1) = 11.004   V(s2) = 8.756\n",
      "\n",
      "iter   39   |   diff: 0.01513   |   V(s0) = 7.881   V(s1) = 11.021   V(s2) = 8.773\n",
      "\n",
      "iter   40   |   diff: 0.01361   |   V(s0) = 7.896   V(s1) = 11.036   V(s2) = 8.788\n",
      "\n",
      "iter   41   |   diff: 0.01225   |   V(s0) = 7.909   V(s1) = 11.049   V(s2) = 8.802\n",
      "\n",
      "iter   42   |   diff: 0.01103   |   V(s0) = 7.922   V(s1) = 11.062   V(s2) = 8.814\n",
      "\n",
      "iter   43   |   diff: 0.00992   |   V(s0) = 7.933   V(s1) = 11.073   V(s2) = 8.825\n",
      "\n",
      "iter   44   |   diff: 0.00893   |   V(s0) = 7.943   V(s1) = 11.083   V(s2) = 8.835\n",
      "\n",
      "iter   45   |   diff: 0.00804   |   V(s0) = 7.952   V(s1) = 11.092   V(s2) = 8.844\n",
      "\n",
      "iter   46   |   diff: 0.00724   |   V(s0) = 7.960   V(s1) = 11.100   V(s2) = 8.852\n",
      "\n",
      "iter   47   |   diff: 0.00651   |   V(s0) = 7.967   V(s1) = 11.107   V(s2) = 8.859\n",
      "\n",
      "iter   48   |   diff: 0.00586   |   V(s0) = 7.973   V(s1) = 11.113   V(s2) = 8.866\n",
      "\n",
      "iter   49   |   diff: 0.00527   |   V(s0) = 7.979   V(s1) = 11.119   V(s2) = 8.872\n",
      "\n",
      "iter   50   |   diff: 0.00475   |   V(s0) = 7.984   V(s1) = 11.125   V(s2) = 8.877\n",
      "\n",
      "iter   51   |   diff: 0.00427   |   V(s0) = 7.989   V(s1) = 11.129   V(s2) = 8.882\n",
      "\n",
      "iter   52   |   diff: 0.00384   |   V(s0) = 7.993   V(s1) = 11.134   V(s2) = 8.886\n",
      "\n",
      "iter   53   |   diff: 0.00346   |   V(s0) = 7.997   V(s1) = 11.137   V(s2) = 8.890\n",
      "\n",
      "iter   54   |   diff: 0.00311   |   V(s0) = 8.001   V(s1) = 11.141   V(s2) = 8.893\n",
      "\n",
      "iter   55   |   diff: 0.00280   |   V(s0) = 8.004   V(s1) = 11.144   V(s2) = 8.896\n",
      "\n",
      "iter   56   |   diff: 0.00252   |   V(s0) = 8.007   V(s1) = 11.147   V(s2) = 8.899\n",
      "\n",
      "iter   57   |   diff: 0.00227   |   V(s0) = 8.009   V(s1) = 11.149   V(s2) = 8.902\n",
      "\n",
      "iter   58   |   diff: 0.00204   |   V(s0) = 8.011   V(s1) = 11.152   V(s2) = 8.904\n",
      "\n",
      "iter   59   |   diff: 0.00184   |   V(s0) = 8.014   V(s1) = 11.154   V(s2) = 8.906\n",
      "\n",
      "iter   60   |   diff: 0.00166   |   V(s0) = 8.015   V(s1) = 11.155   V(s2) = 8.908\n",
      "\n",
      "iter   61   |   diff: 0.00149   |   V(s0) = 8.017   V(s1) = 11.157   V(s2) = 8.909\n",
      "\n",
      "iter   62   |   diff: 0.00134   |   V(s0) = 8.019   V(s1) = 11.159   V(s2) = 8.911\n",
      "\n",
      "iter   63   |   diff: 0.00121   |   V(s0) = 8.020   V(s1) = 11.160   V(s2) = 8.912\n",
      "\n",
      "iter   64   |   diff: 0.00109   |   V(s0) = 8.021   V(s1) = 11.161   V(s2) = 8.913\n",
      "\n",
      "iter   65   |   diff: 0.00098   |   V(s0) = 8.022   V(s1) = 11.162   V(s2) = 8.915\n",
      "\n",
      "Terminated\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "gamma = 0.9            # discount for MDP\n",
    "num_iter = 100         # maximum iterations, excluding initialization\n",
    "min_difference = 0.001 # stop VI if new values are this close to old values (or closer)\n",
    "\n",
    "# initialize V(s)\n",
    "state_values = {s : 0 for s in mdp.get_all_states()}\n",
    "\n",
    "\n",
    "for i in range(num_iter):\n",
    "    \n",
    "    # Compute new state values using the functions you defined above. It must be a dict {state : new_V(state)}\n",
    "    new_state_values = {}\n",
    "    for state in mdp.get_all_states():\n",
    "        new_state_values[state] = get_new_state_value(mdp, state_values, state, gamma)\n",
    "    assert isinstance(new_state_values, dict)\n",
    "    \n",
    "    # Compute difference\n",
    "    diff = max(abs(new_state_values[s] - state_values[s]) for s in mdp.get_all_states())\n",
    "    print(\"iter %4i   |   diff: %6.5f   |   \"%(i, diff), end=\"\")\n",
    "    print('   '.join(\"V(%s) = %.3f\"%(s, v) for s,v in state_values.items()), end='\\n\\n')\n",
    "    state_values = new_state_values\n",
    "    \n",
    "    if diff < min_difference:\n",
    "        print(\"Terminated\"); break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final state values: {'s0': 8.023123818663871, 's1': 11.163174814980803, 's2': 8.915559364985523}\n"
     ]
    }
   ],
   "source": [
    "print(\"Final state values:\", state_values)\n",
    "\n",
    "assert abs(state_values['s0'] - 8.032)  < 0.01\n",
    "assert abs(state_values['s1'] - 11.169) < 0.01\n",
    "assert abs(state_values['s2'] - 8.921)  < 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use those $V^{*}(s)$ to find optimal actions in each state\n",
    "\n",
    " $$\\pi^*(s) = argmax_a \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')] = argmax_a Q_i(s,a)$$\n",
    " \n",
    "The only difference vs V(s) is that here we take not max but argmax: find action such with maximum Q(s,a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_action(mdp, state_values, state, gamma=0.9):\n",
    "    \"\"\" Finds optimal action using formula above. \"\"\"\n",
    "    if mdp.is_terminal(state): return None\n",
    "    actions = {}\n",
    "    for action in mdp.get_possible_actions(state):\n",
    "        actions[action] = get_action_value(mdp, state_values, state, action, gamma)\n",
    "    return max(actions, key=actions.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_optimal_action(mdp, state_values, 's0', gamma) == 'a1'\n",
    "assert get_optimal_action(mdp, state_values, 's1', gamma) == 'a0'\n",
    "assert get_optimal_action(mdp, state_values, 's2', gamma) == 'a0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average reward:  0.9145\n"
     ]
    }
   ],
   "source": [
    "# Measure agent's average reward\n",
    "\n",
    "s = mdp.reset()\n",
    "rewards = []\n",
    "for _ in range(10000):\n",
    "    s, r, done, _ = mdp.step(get_optimal_action(mdp, state_values, s, gamma))\n",
    "    rewards.append(r)\n",
    "    \n",
    "print(\"average reward: \", np.mean(rewards))\n",
    "\n",
    "assert(0.85 < np.mean(rewards) < 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frozen lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*FFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mdp import FrozenLakeEnv\n",
    "mdp = FrozenLakeEnv(slip_chance=0)\n",
    "\n",
    "mdp.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(mdp, state_values=None, gamma = 0.9, num_iter = 1000, min_difference = 1e-5):\n",
    "    \"\"\" performs num_iter value iteration steps starting from state_values. Same as before but in a function \"\"\"\n",
    "    state_values = state_values or {s : 0 for s in mdp.get_all_states()}\n",
    "    for i in range(num_iter):\n",
    "\n",
    "        # Compute new state values using the functions you defined above. It must be a dict {state : new_V(state)}\n",
    "        new_state_values = {}\n",
    "        for state in mdp.get_all_states():\n",
    "            new_state_values[state] = get_new_state_value(mdp, state_values, state, gamma)\n",
    "\n",
    "        assert isinstance(new_state_values, dict)\n",
    "\n",
    "        # Compute difference\n",
    "        diff = max(abs(new_state_values[s] - state_values[s]) for s in mdp.get_all_states())\n",
    "        print(\"iter %4i   |   diff: %6.5f   |   V(start): %.3f \"%(i, diff, new_state_values[mdp._initial_state]))\n",
    "        \n",
    "        state_values = new_state_values\n",
    "        if diff < min_difference:\n",
    "            print(\"Terminated\"); break\n",
    "            \n",
    "    return state_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 1.00000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.90000   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.81000   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.72900   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.65610   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.59049   |   V(start): 0.590 \n",
      "iter    6   |   diff: 0.00000   |   V(start): 0.590 \n",
      "Terminated\n"
     ]
    }
   ],
   "source": [
    "state_values = value_iteration(mdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down\n",
      "\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFF*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = mdp.reset()\n",
    "mdp.render()\n",
    "for t in range(100):\n",
    "    clear_output(True)\n",
    "    sleep(0.5)\n",
    "    a = get_optimal_action(mdp, state_values, s, gamma)\n",
    "    print(a, end='\\n\\n')\n",
    "    s, r, done, _ = mdp.step(a)\n",
    "    mdp.render()\n",
    "    if done: break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualize!\n",
    "\n",
    "It's usually interesting to see what your algorithm actually learned under the hood. To do so, we'll plot state value functions and optimal actions at each VI step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def draw_policy(mdp, state_values):\n",
    "    plt.figure(figsize=(3,3))\n",
    "    h,w = mdp.desc.shape\n",
    "    states = sorted(mdp.get_all_states())\n",
    "    V = np.array([state_values[s] for s in states])\n",
    "    Pi = {s: get_optimal_action(mdp, state_values, s, gamma) for s in states}\n",
    "    plt.imshow(V.reshape(w,h), cmap='gray', interpolation='none', clim=(0,1))\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks(np.arange(h)-.5)\n",
    "    ax.set_yticks(np.arange(w)-.5)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    Y, X = np.mgrid[0:4, 0:4]\n",
    "    a2uv = {'left': (-1, 0), 'down':(0, -1), 'right':(1,0), 'up':(-1, 0)}\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            plt.text(x, y, str(mdp.desc[y,x].item()),\n",
    "                     color='g', size=12,  verticalalignment='center',\n",
    "                     horizontalalignment='center', fontweight='bold')\n",
    "            a = Pi[y, x]\n",
    "            if a is None: continue\n",
    "            u, v = a2uv[a]\n",
    "            plt.arrow(x, y,u*.3, -v*.3, color='m', head_width=0.1, head_length=0.1) \n",
    "    plt.grid(color='b', lw=2, ls='-')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 9\n",
      "iter    0   |   diff: 0.08037   |   V(start): 0.000 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state_values = {s : 0 for s in mdp.get_all_states()}\n",
    "\n",
    "for i in range(10):\n",
    "    clear_output(True)\n",
    "    print(\"after iteration %i\"%i)\n",
    "    state_values = value_iteration(mdp, state_values, num_iter=1)\n",
    "    draw_policy(mdp, state_values)\n",
    "    sleep(0.5)\n",
    "# please ignore iter 0 at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['S', 'F', 'F', 'F', 'F', 'F', 'F', 'F'],\n",
       "       ['F', 'F', 'F', 'F', 'F', 'F', 'F', 'F'],\n",
       "       ['F', 'F', 'F', 'H', 'F', 'F', 'F', 'F'],\n",
       "       ['F', 'F', 'F', 'F', 'F', 'H', 'F', 'F'],\n",
       "       ['F', 'F', 'F', 'H', 'F', 'F', 'F', 'F'],\n",
       "       ['F', 'H', 'H', 'F', 'F', 'F', 'H', 'F'],\n",
       "       ['F', 'H', 'F', 'F', 'H', 'F', 'H', 'F'],\n",
       "       ['F', 'F', 'F', 'H', 'F', 'F', 'F', 'G']], dtype='<U1')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdp.desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 29\n",
      "iter    0   |   diff: 0.00000   |   V(start): 0.198 \n",
      "Terminated\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "mdp = FrozenLakeEnv(map_name='8x8',slip_chance=0.1)\n",
    "state_values = {s : 0 for s in mdp.get_all_states()}\n",
    "\n",
    "for i in range(30):\n",
    "    clear_output(True)\n",
    "    print(\"after iteration %i\"%i)\n",
    "    state_values = value_iteration(mdp, state_values, num_iter=1)\n",
    "    draw_policy(mdp, state_values)\n",
    "    sleep(0.5)\n",
    "# please ignore iter 0 at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Massive tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 1.00000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.90000   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.81000   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.72900   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.65610   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.59049   |   V(start): 0.590 \n",
      "iter    6   |   diff: 0.00000   |   V(start): 0.590 \n",
      "Terminated\n",
      "average reward:  1.0\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "mdp = FrozenLakeEnv(slip_chance=0)\n",
    "state_values = value_iteration(mdp)\n",
    "\n",
    "total_rewards = []\n",
    "for game_i in range(1000):\n",
    "    s = mdp.reset()\n",
    "    rewards = []\n",
    "    for t in range(100):\n",
    "        s, r, done, _ = mdp.step(get_optimal_action(mdp, state_values, s, gamma))\n",
    "        rewards.append(r)\n",
    "        if done: break\n",
    "    total_rewards.append(np.sum(rewards))\n",
    "    \n",
    "print(\"average reward: \", np.mean(total_rewards))\n",
    "assert(1.0 <= np.mean(total_rewards) <= 1.0)\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 0.90000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.72900   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.62330   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.50487   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.40894   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.34868   |   V(start): 0.349 \n",
      "iter    6   |   diff: 0.06529   |   V(start): 0.410 \n",
      "iter    7   |   diff: 0.05832   |   V(start): 0.468 \n",
      "iter    8   |   diff: 0.01139   |   V(start): 0.480 \n",
      "iter    9   |   diff: 0.00764   |   V(start): 0.487 \n",
      "iter   10   |   diff: 0.00164   |   V(start): 0.489 \n",
      "iter   11   |   diff: 0.00094   |   V(start): 0.490 \n",
      "iter   12   |   diff: 0.00022   |   V(start): 0.490 \n",
      "iter   13   |   diff: 0.00011   |   V(start): 0.490 \n",
      "iter   14   |   diff: 0.00003   |   V(start): 0.490 \n",
      "iter   15   |   diff: 0.00001   |   V(start): 0.490 \n",
      "iter   16   |   diff: 0.00000   |   V(start): 0.490 \n",
      "Terminated\n",
      "average reward:  0.893\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# Measure agent's average reward\n",
    "mdp = FrozenLakeEnv(slip_chance=0.1)\n",
    "state_values = value_iteration(mdp)\n",
    "\n",
    "total_rewards = []\n",
    "for game_i in range(1000):\n",
    "    s = mdp.reset()\n",
    "    rewards = []\n",
    "    for t in range(100):\n",
    "        s, r, done, _ = mdp.step(get_optimal_action(mdp, state_values, s, gamma))\n",
    "        rewards.append(r)\n",
    "        if done: break\n",
    "    total_rewards.append(np.sum(rewards))\n",
    "    \n",
    "print(\"average reward: \", np.mean(total_rewards))\n",
    "assert(0.8 <= np.mean(total_rewards) <= 0.95)\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 0.75000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.50625   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.39867   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.26910   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.18164   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.14013   |   V(start): 0.140 \n",
      "iter    6   |   diff: 0.07028   |   V(start): 0.199 \n",
      "iter    7   |   diff: 0.06030   |   V(start): 0.260 \n",
      "iter    8   |   diff: 0.02594   |   V(start): 0.285 \n",
      "iter    9   |   diff: 0.01918   |   V(start): 0.305 \n",
      "iter   10   |   diff: 0.00858   |   V(start): 0.313 \n",
      "iter   11   |   diff: 0.00560   |   V(start): 0.319 \n",
      "iter   12   |   diff: 0.00260   |   V(start): 0.321 \n",
      "iter   13   |   diff: 0.00159   |   V(start): 0.323 \n",
      "iter   14   |   diff: 0.00076   |   V(start): 0.324 \n",
      "iter   15   |   diff: 0.00045   |   V(start): 0.324 \n",
      "iter   16   |   diff: 0.00022   |   V(start): 0.324 \n",
      "iter   17   |   diff: 0.00012   |   V(start): 0.325 \n",
      "iter   18   |   diff: 0.00006   |   V(start): 0.325 \n",
      "iter   19   |   diff: 0.00003   |   V(start): 0.325 \n",
      "iter   20   |   diff: 0.00002   |   V(start): 0.325 \n",
      "iter   21   |   diff: 0.00001   |   V(start): 0.325 \n",
      "Terminated\n",
      "average reward:  0.651\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# Measure agent's average reward\n",
    "mdp = FrozenLakeEnv(slip_chance=0.25)\n",
    "state_values = value_iteration(mdp)\n",
    "\n",
    "total_rewards = []\n",
    "for game_i in range(1000):\n",
    "    s = mdp.reset()\n",
    "    rewards = []\n",
    "    for t in range(100):\n",
    "        s, r, done, _ = mdp.step(get_optimal_action(mdp, state_values, s, gamma))\n",
    "        rewards.append(r)\n",
    "        if done: break\n",
    "    total_rewards.append(np.sum(rewards))\n",
    "    \n",
    "print(\"average reward: \", np.mean(total_rewards))\n",
    "assert(0.6 <= np.mean(total_rewards) <= 0.7)\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 0.80000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.57600   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.41472   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.29860   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.24186   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.19349   |   V(start): 0.000 \n",
      "iter    6   |   diff: 0.15325   |   V(start): 0.000 \n",
      "iter    7   |   diff: 0.12288   |   V(start): 0.000 \n",
      "iter    8   |   diff: 0.09930   |   V(start): 0.000 \n",
      "iter    9   |   diff: 0.08037   |   V(start): 0.000 \n",
      "iter   10   |   diff: 0.06426   |   V(start): 0.000 \n",
      "iter   11   |   diff: 0.05129   |   V(start): 0.000 \n",
      "iter   12   |   diff: 0.04330   |   V(start): 0.000 \n",
      "iter   13   |   diff: 0.03802   |   V(start): 0.033 \n",
      "iter   14   |   diff: 0.03332   |   V(start): 0.058 \n",
      "iter   15   |   diff: 0.02910   |   V(start): 0.087 \n",
      "iter   16   |   diff: 0.01855   |   V(start): 0.106 \n",
      "iter   17   |   diff: 0.01403   |   V(start): 0.120 \n",
      "iter   18   |   diff: 0.00810   |   V(start): 0.128 \n",
      "iter   19   |   diff: 0.00555   |   V(start): 0.133 \n",
      "iter   20   |   diff: 0.00321   |   V(start): 0.137 \n",
      "iter   21   |   diff: 0.00247   |   V(start): 0.138 \n",
      "iter   22   |   diff: 0.00147   |   V(start): 0.139 \n",
      "iter   23   |   diff: 0.00104   |   V(start): 0.140 \n",
      "iter   24   |   diff: 0.00058   |   V(start): 0.140 \n",
      "iter   25   |   diff: 0.00036   |   V(start): 0.141 \n",
      "iter   26   |   diff: 0.00024   |   V(start): 0.141 \n",
      "iter   27   |   diff: 0.00018   |   V(start): 0.141 \n",
      "iter   28   |   diff: 0.00012   |   V(start): 0.141 \n",
      "iter   29   |   diff: 0.00007   |   V(start): 0.141 \n",
      "iter   30   |   diff: 0.00004   |   V(start): 0.141 \n",
      "iter   31   |   diff: 0.00003   |   V(start): 0.141 \n",
      "iter   32   |   diff: 0.00001   |   V(start): 0.141 \n",
      "iter   33   |   diff: 0.00001   |   V(start): 0.141 \n",
      "Terminated\n",
      "average reward:  0.744\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# Measure agent's average reward\n",
    "mdp = FrozenLakeEnv(slip_chance=0.2, map_name='8x8')\n",
    "state_values = value_iteration(mdp)\n",
    "\n",
    "total_rewards = []\n",
    "for game_i in range(1000):\n",
    "    s = mdp.reset()\n",
    "    rewards = []\n",
    "    for t in range(100):\n",
    "        s, r, done, _ = mdp.step(get_optimal_action(mdp, state_values, s, gamma))\n",
    "        rewards.append(r)\n",
    "        if done: break\n",
    "    total_rewards.append(np.sum(rewards))\n",
    "    \n",
    "print(\"average reward: \", np.mean(total_rewards))\n",
    "assert(0.6 <= np.mean(total_rewards) <= 0.8)\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit to coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from submit import submit_assigment\n",
    "submit_assigment(\n",
    "    get_action_value, \n",
    "    get_new_state_value, \n",
    "    get_optimal_action, \n",
    "    value_iteration, \n",
    "    <EMAIL>, \n",
    "    <TOKEN>)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
